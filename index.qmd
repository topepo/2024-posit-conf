---
title: "Evaluating Time-to-Event Models is Hard"
author: "Max Kuhn"
format: 
  revealjs:
    include-before-body: header.html
    include-after-body: footer-annotations.html    
editor: source
knitr:
  opts_chunk: 
    echo: true
    collapse: true
    comment: "#>"
---

# bit.ly/2024-posit-conf

```{r}
#| label: initialize
#| echo: false

library(tidymodels)
library(censored)
tidymodels_prefer()
theme_set(theme_bw())
options(pillar.advice = FALSE, pillar.min_title_chars = Inf)
```

```{r}
#| label: model-fit
#| echo: false
#| cache: true

data("mlc_churn")

mlc_churn <-
  mlc_churn %>%
  mutate(
    churned = ifelse(churn == "yes", 1, 0),
    event_time = Surv(account_length, churned)
  ) %>%
  select(-churned, account_length)


set.seed(1)
churn_split <- initial_validation_split(mlc_churn)
churn_tr <- training(churn_split)
churn_te <- testing(churn_split)
churn_val <- validation(churn_split)
churn_rs <- validation_set(churn_split)

# ------------------------------------------------------------------------------

event_metrics <- metric_set(brier_survival, roc_auc_survival)

mod_res <- 
  rand_forest()  %>% 
  set_engine("aorsf")  %>% 
  set_mode("censored regression")  %>%
  fit_resamples(
    event_time ~ ., 
    resamples = churn_rs, 
    metrics = event_metrics,
    eval_time = 5:230,
    control = control_resamples(save_pred = TRUE, save_workflow = TRUE)
  )

mod_fit <- fit_best(mod_res)
rkm_curve <- 
  mod_fit$fit$fit$censor_probs$fit[1:7] %>% 
  as_tibble()

val_pred <- collect_predictions(mod_res)
val_ind <- c(580, # event at time 17.0
             721, # censored at time 17.0
             426  # event at 100.0
             )
val_example <- val_pred[val_ind,]
```

## Probability Predictions

```{r}
#| label: three-examples
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: 80%
#| fig-align: center
three_examples <- 
  val_example %>% 
  mutate(example = as.character(event_time)) %>% 
  unnest(.pred) %>% 
  ggplot(aes(.eval_time, .pred_survival, id = example, col = example)) +
  geom_step() + 
  labs(x = "Time", y = "Probability of Survival") +
  theme(legend.position = "top")
three_examples
```

## Compute Metrics at Specific  Times

```{r}
#| label: eval-times
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: 80%
#| fig-align: center
three_examples + 
  geom_vline(xintercept = (1:7) * 30, lty = 3)
```

## Classification(ish) Metrics

Most dynamic metrics convert the observed event time to a binary event/non-event representation (at a specific evaluation time). 

From there, we can apply existing classification metrics, such as

- Brier Score (for calibration)
- Area under the ROC curve (for separation)

Weâ€™ll talk about both of these. 

There are more details on dynamics metrics at [tidymodels.org](https://www.tidymodels.org/learn/#category=survival%20analysis). 

## Converting to Events 

For a specific evaluation time point $\tau$, we convert the observed event time to a binary event/non-event version (if possible) ($y_{i\tau} \in \{0, 1\}$). 

$$
y_{i\tau} = 
\begin{cases}
1 & \text{if } t_{i} \leq \tau\text{ and  event} \notag \\ 
0 & \text{if } t_{i} \gt \tau \text{ and } either \notag \\ 
missing & \text{if } t_{i} \leq \tau\text{ and censored }
\end{cases}
$$

## Converting to Events

```{r}
#| label: plot-graf-categories
#| echo: false
#| warning: false
#| fig-width: 8
#| fig-height: 4
#| out-width: 70%
#| fig-align: center
obs_time <- c(4, 2)
obs_status <- c("censored", "event")

df1 <- tibble::tibble(
  obs_id = 1:2,
  obs_time = obs_time,
  obs_status = obs_status,
  eval_time = 1,
  eval_status = c("censored", "censored")
)
df2 <- tibble::tibble(
  obs_id = 1:2,
  obs_time = obs_time,
  obs_status = obs_status,
  eval_time = 3,
  eval_status = c("censored", "event")
)
df3 <- tibble::tibble(
  obs_id = 1:2,
  obs_time = obs_time,
  obs_status = obs_status,
  eval_time = 5,
  eval_status = c(NA, "event")
)
df <- bind_rows(df1, df2, df3)

pch_dot_empty <- 1
pch_dot_solid <- 19
pch_triangle_empty <- 2
pch_triangle_solid <- 17

df %>%
  dplyr::mutate(
    obs_status = dplyr::if_else(obs_status == "censored", pch_dot_empty, pch_dot_solid),
    eval_status = dplyr::if_else(
      eval_status == "censored",
      pch_triangle_empty,
      pch_triangle_solid
    ),
    eval_time_label = factor(paste("Evaluation Time =", eval_time))
  ) %>% 
  ggplot() +
  geom_point(aes(obs_time, obs_id, shape = obs_status, size = I(5))) +
  geom_segment(aes(
    x = rep(0, 6),
    y = obs_id,
    xend = obs_time,
    yend = obs_id
  )) +
  geom_vline(aes(
    xintercept = eval_time,
    col = I("red"),
    linetype = I("dashed"),
    linewidth = I(0.8)
  )) +
  geom_point(aes(
    eval_time,
    obs_id,
    shape = eval_status,
    col = I("red"),
    size = I(5)
  )) +
  scale_shape_identity(
    "Status",
    labels = c(
      "Observation: censored",
      "Observation: event",
      "Evaluation: non-event",
      "Evaluation: event"
    ),
    breaks = c(1, 19, 2, 17),
    guide = "legend"
  ) +
  scale_x_continuous(limits = c(0, 7)) +
  scale_y_continuous(limits = c(0.5, 2.5)) +
  labs(x = "Time", y = "Sample") +
  theme_bw() +
  theme(axis.text.y = element_blank(), legend.position = "top") +
  facet_grid( ~ eval_time_label) 
```

## Dealing with Missing Outcome Data

Without censored data points, this conversion would yield appropriate performance estimates since no event outcomes would be missing. 

* Otherwise, there is the potential for bias due to missingness. 

<br>

We'll use tools from causal inference to compensate by creating a **propensity score** that uses the probability of being censored/missing. 

## Censoring Weights

We currently use a simple, non-informative censoring model called a "reverse Kaplan-Meier" curve. 

<br>

For a given evaluation time, we can compute the probability of any sampleing being censored at $\tau$. 

<br>

Our metrics use case weights use the inverse of this probability. See [Graf _et al_ (1999)](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C7&q=graf+1999+%22Assessment+and+comparison+of+prognostic+classification+schemes+for+survival+data%22&btnG=).



```{r}
#| label: unambiguous-calc
#| echo: false
val_pred_long <- 
  val_pred %>% 
  add_rowindex() %>% 
  select(.row, .pred) %>% 
  unnest(.pred)

prob_stats <- 
  val_pred_long %>% 
  summarize(
    `Sample Size` = sum(!is.na(.weight_censored)),
    sum = sum(.weight_censored, na.rm = TRUE),
    skewness = e1071::skewness(.weight_censored, na.rm = TRUE),
    .by = c(.eval_time))
```

## Sum of Weights Over Time

```{r}
#| label: unambiguous-sum
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: 80%
#| fig-align: center
prob_stats %>% 
  ggplot(aes(.eval_time, sum, col = `Sample Size`)) + 
  geom_step() + 
  labs(x = "Evaluation Time", y = "Sum of Weights")
```



## Brier Score

The Brier score is **calibration** metric originally meant for classification models:

$$
Brier = \frac{1}{N}\sum_{i=1}^N\sum_{k=1}^C (y_{ik} - \hat{\pi}_{ik})^2
$$

For our application, we have two classes and case weights

$$
Brier_{\tau} = \frac{1}{W_\tau}\sum_{i=1}^N\sum_{k=1}^C w_{it}(y_{ik\tau} - \hat{\pi}_{ik\tau})^2
$$

## Brier Score Code

```{r}
#| label: brier-ex
# Out-of-sample predictions at many time points
# Results contain survival probabilities and case weights in a 
# list column called `.pred`
val_pred <- augment(mod_fit, new_data = churn_val, eval_time = 5:230)

val_brier <- brier_survival(val_pred, truth = event_time, .pred)
val_brier %>% filter(.eval_time %in% seq(30, 210, by = 30))
```


## Integrated Brier Score

```{r}
#| label: brier-int-ex
brier_survival_integrated(val_pred, truth = event_time, .pred)
```



## Brier Scores Over Evaluation Time {.annotation} 

```{r}
#| label: brier-time
#| echo: false
#| fig-width: 6
#| fig-height: 4.25
#| out-width: 60%
#| fig-align: center
val_brier %>% 
  ggplot(aes(.eval_time, .estimate)) + 
  geom_line() + 
  geom_hline(yintercept = 0, col = "green") + 
  geom_hline(yintercept = .25, col = "red", lty = 2)  +
  labs(x = "Evaluation time", y = "Brier score")
```

## Calibration Over Time

```{r}
#| label: calibration-time
#| echo: false
#| fig-width: 10
#| fig-height: 5
#| out-width: 10%
#| fig-align: center
time_as_binary_event <- function(surv, eval_time) {
  event_time <- .extract_surv_time(surv)
  status <- .extract_surv_status(surv)
  is_event_before_t <- event_time <= eval_time & status == 1
  
  # Three possible contributions to the statistic from Graf 1999
  # Censoring time before eval_time, no contribution (Graf category 3)
  binary_res <- rep(NA_character_, length(event_time))
  
  # A real event prior to eval_time (Graf category 1)
  binary_res <- if_else(is_event_before_t, "event", binary_res)
  
  # Observed time greater than eval_time (Graf category 2)
  binary_res <- if_else(event_time > eval_time, "non-event", binary_res)
  factor(binary_res, levels = c("event", "non-event"))
}

# Unnest the list columns and convert the event time data to binary format 
binary_encoding <- 
  val_pred %>% 
  select(.pred, event_time) %>% 
  add_rowindex() %>% 
  unnest(.pred) %>% 
  mutate(
    obs_class = time_as_binary_event(event_time, .eval_time),
    pred_class = if_else(.pred_survival >= 1 / 2, "non-event", "event"),
    pred_class = factor(pred_class, levels = c("event", "non-event"))
  )

cal_data <- NULL

for (highlight_time in seq(40, 220, by = 40)) {
  
  highlight_data <- 
    binary_encoding %>% 
    filter(.eval_time == highlight_time & !is.na(.weight_censored)) %>% 
    select(.eval_time, .pred_survival, .weight_censored, obs_class, pred_class, event_time)  %>% 
    filter(!is.na(.weight_censored)) %>% 
    mutate(
      group = cut(.pred_survival, breaks = (0:10)/10, include.lowest = TRUE)
    )  %>% 
    group_nest(group)  %>% 
    mutate(
      numer = map_dbl(data, ~ sum(.x$ .weight_censored[.x$obs_class == "non-event"])),
      denom = map_dbl(data, ~ sum(.x$ .weight_censored)),
      rate = numer/denom,
      n = map_int(data, nrow),
      log10_n = log10(map_int(data, nrow)),
      midpoint = (row_number() - 1) + 1/2,
      midpoint = row_number()/n(),
      highlight_time = highlight_time
    ) 

  cal_data <- bind_rows(cal_data, highlight_data)
  
}

cal_data %>% 
  mutate(evaluation_time = paste("Time =", format(highlight_time))) %>% 
  ggplot(aes(midpoint, rate, size = n)) + 
  geom_abline(lty = 3) +
  geom_point(alpha = 1/ 2) + 
  coord_obs_pred(xlim = 0:1, ylim = 0:1) +
  scale_size_continuous(transform = scales::transform_log10(), 
                        range = c(0.5, 6),
                        breaks = c(1, 10, 30, 100, 300, 1000)) +
  facet_wrap(~ evaluation_time, nrow = 1) +
  theme(legend.position = "top") +
  labs(y = "Event Rate", x = "Bin Midpoint")
```  

## Area Under the ROC Curve

This is more straightforward. 

<br>

We can use the standard ROC curve machinery once we have the indicators, probabilities, and censoring weights at evaluation time $\tau$ ([Hung and Chiang (2010)](https://scholar.google.com/scholar?hl=en&as_sdt=0%2C7&q=%22Optimal+Composite+Markers+for+Time-Dependent+Receiver+Operating+Characteristic+Curves+with+Censored+Survival+Data%22&btnG=)). 

<br>

ROC curves measure the **separation** between events and non-events and are ignorant of how well-calibrated the probabilities are.  


## Area Under the ROC Curve 

```{r auc-survival}
val_roc_auc <- roc_auc_survival(val_pred, truth = event_time, .pred)
val_roc_auc %>% filter(.eval_time %in% seq(30, 210, by = 30))
```

## ROC AUC Over Evaluation Time

```{r}
#| label: auc-time
#| echo: false
#| fig-width: 6
#| fig-height: 4.25
#| out-width: 60%
#| fig-align: center
val_roc_auc %>% 
  ggplot(aes(.eval_time, .estimate)) + 
  geom_hline(yintercept = 1, col = "green") +
  geom_hline(yintercept = 1/2, col = "red") + 
  geom_line() +
  labs(x = "Evaluation time", y = "ROC AUC")
```

## Conculsion

- Bad news: statistically, this is pretty convoluted. 

- Good news: tidymodels handles the details and provides a clean syntax for some complex statistics. 

<br> 

A huge thanks to the tidymodels team: Hannah Frick, Emil Hvitfeldt, and Simon Couch!


# Details

## "Reverse Kaplan-Meier" Curve

:::: {.columns}

::: {.column width="50%"}

We assume a non-informative censoring model: to compute the probability

```{r}
#| label: rkm
#| echo: false
#| fig-width: 6
#| fig-height: 4
#| out-width: 100%
#| fig-align: center
rkm_curve %>% 
  ggplot(aes(time, surv)) + 
  geom_step() + 
  labs(x = "Time", y = "Probability of Censoring")
```



:::


::: {.column width="50%"}

For each prediction at evaluation time $\tau$, we compute the probability at an _adjusted time_: 

$$
t_i^*= 
\begin{cases}
t_i  - \epsilon &  \text{if }t_i \le \tau \\ \notag
\tau - \epsilon &  \text{if }t_i > \tau  \notag 
\end{cases}
$$

:::


::::

